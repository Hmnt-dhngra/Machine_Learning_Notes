{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59595cc4-178f-4111-8c6a-6c0cf2d32fb5",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587a602-79dc-484e-8863-a8485b5ce03c",
   "metadata": {},
   "source": [
    "You should be able to take decisions backed by data. \n",
    "You cannot hard code all the complexities in terms of the coded logics . \n",
    "Machine learning started in 1950, but we were not having enough data that time, further the computation power wasn't sufficient and economical.  \n",
    "Data --> EDA --> FE--> ML--> features --> Task complete\n",
    "Artificial Intelligence : System that can perform tasks that typically require human intelligence. \n",
    "\n",
    "Machine learning is what is used to achieve Artificial intelligence. \n",
    "Machine learning : Systems that improve performance on some tasks by learning the data \n",
    "Systems that can solve taks without the need to program everything explicitly\n",
    "Machine learning is a specificalisation of AI. \n",
    "\n",
    "Deep learning is a subset of machine learning which uses neural networks which are inspired from human brain \n",
    "\n",
    "AI can be actually an amalgation of Rule based systems + Ml systems + reinforcement learning + NLP + Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb697496-2ac8-464e-b885-714c4311bacf",
   "metadata": {},
   "source": [
    "Machine learning : Machine is learning (finding patterns) \n",
    "There are 3 methods in which the machine is learning \n",
    "\n",
    "- Supervised learning : When members of a team need feedback of the supervisor to confirm if they are doing the work correctly. Similarly understand the members as Features or questions and the target as the answers , so we are telling the machine that so is the answer when this question comes up.\n",
    "  -- Features are like the input variables or known as independant variables. \n",
    "  -- targets are the labels or the known output or the ground truth also known as the dependant variables. \n",
    "  -- for deciding the income in a new job, you will need to know the applicant's age, years of experience and tech stack, hence all these are indepdant and these together defines the income which is why iot is dependant\n",
    "  Question we ask from ML model: Given data, predict some answer \n",
    "\n",
    "- Unsupervised learning : we learn to find pattern and ultimately we group the data. Features --> ML --> groups.\n",
    "  -- Question we ask from ML model: Given the data, segment into the groups.   \n",
    "\n",
    "\n",
    "- Reinforcement learning : closest to how the humans learn. A RL agent takes action and based on it is goven a reward or a penalty. Example : Autonomous cars, robotics, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c8467-f246-417d-b2ba-df2ed15f66ed",
   "metadata": {},
   "source": [
    "## Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c3a31-cf92-49a8-bf43-7f426fa8b354",
   "metadata": {},
   "source": [
    "### Machine learning prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0c469-9f6d-4ad7-9f76-9d9d37d138e8",
   "metadata": {},
   "source": [
    "#### 1. Data splitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235647b-fa1e-4f07-8a64-54431bce4357",
   "metadata": {},
   "source": [
    "Data splitting  : create 2 sets of data, one that the modela has already seen and the othe ron which it will be tested. \n",
    "- Training set \n",
    "- Test set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7c6d2-c6b8-4e20-a415-525c4fbf4cd0",
   "metadata": {},
   "source": [
    "Data splitting  : create 3 sets of data, \n",
    "one that the modela has already seen, \n",
    "the other on which its learnings will be validated \n",
    "and the third on which it will be tested. \n",
    "- Training set \n",
    "- Validation set \n",
    "- Test set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac3534-f94d-4916-8904-82e45a11e060",
   "metadata": {},
   "source": [
    "we will make a model, \n",
    "and check the model accuracy on the validation data say 70 %, \n",
    "then we will change some parameters, again validate and observe the model accuracy to be 76%\n",
    "Now we will test on the test data and check the accuracy --> say 72% i.e. very near to the validation set ...Okay good. \n",
    "\n",
    "If it is away from the validation set accuracy, we will need to do some tweaks. \n",
    "We do this by checking the constituents of each of the three data and do a mix of the three data points to ultimately train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9458e4ba-2109-4c75-9c44-420916eb770a",
   "metadata": {},
   "source": [
    "train test split ratio is not universal , depends on what the data is. \n",
    "For good enough data say > 3000, we can follow : \n",
    "- Train 70-80 %\n",
    "- Test 20-30 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372c8f8-378f-44ef-be63-0084c24042c5",
   "metadata": {},
   "source": [
    "train val test split ratio is not universal , depends on what the data is. \n",
    "For good enough data say > 3000, we can follow : \n",
    "- Train 70 %\n",
    "- Val 20 %\n",
    "- Test 10 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7261c3e-1ea2-4e74-adca-7a9990917946",
   "metadata": {},
   "source": [
    "for x1=2, x2=3 you have y = 10 and ML predicted y(hat)=3\n",
    "\n",
    "There needs to be a mechanism that tells how wrong the predicted value is versus the actual value. \n",
    "This functionality of comparing is called evaluation and you make evluation metrics which help you decide how well is the model learning or is it a good model or not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd08c98-39a3-4616-852b-972ca8bf8055",
   "metadata": {},
   "source": [
    "Error is the difference between the actual value and the predicted value. \n",
    "Error calculation : It is usually of 2 types : \n",
    "- For each data point ==> Loss function. We use loss function to check error on single single data points.  \n",
    "- for the set of data (train, validation, etc) ==> Cost function i.e. We use cost function to calculate total error of your data set\n",
    "Now you compute errors, y - y(hat) for all the data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1db62-5eae-44cf-9092-e59f9b95c9b6",
   "metadata": {},
   "source": [
    "Say for example you have a train data and you want to check the model performance, you will use cost function which ofcourse internally will use a loss function to calculate loss on each data point. \n",
    "Train set error calculation --> you need a cost function --> you calculate loss on each data point using a loss function (a formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b6252-3639-44f2-85b2-2765b68b4741",
   "metadata": {},
   "source": [
    "- If training loss << test/validation loss ====> Model Over fitting. \n",
    "The model has learnt all the patterns in the training set but couldn't capture the intricacies of the test data. We perform superb on the training data but poorly on the test data. \n",
    "\n",
    "- If training loss == Test/validation loss, that's an ideal case. Though it's not a technical term, it is used for a general clarity.\n",
    "\n",
    "- If training loss >>> test /validation loss ===> Model Underfitting. Usually here both training loss and test/validation loss is bad. \n",
    "The model is not understanding the basic patterns in the training data.\n",
    "In Train, the model has 30 % accuracy, in test the accuracy is 50 % . Why ?\n",
    "2 factors possible \n",
    "- sample is small\n",
    "- Randomness. Those cases of train where the model is performing good are part of test also 'majorly', the test accuracy will be better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107f35e-4f8d-44bc-b631-101e114f0254",
   "metadata": {},
   "source": [
    "Types of evaluation metrics (FOR REGRESSION): \n",
    "- summation of all the errors/loss \n",
    "- averaging of all the errors/loss\n",
    "- Mean squared error (MSE) -> Mean of squared errors. The squaring is done to penalise the one having more error much analogous to the subject in which the student scored the least need to be focussed more because that subject has the most error i.e. deviation from the ideal i.e 100.\n",
    "- Mean absolute error (MAE) -> Mean of absolute errors.\n",
    "- Root mean square error (RMSE) -> The root of Mean of squared errors. Used when MSE is giving very large values.\n",
    "- Modified Mean squared error (mMSE) -> kind of half of RMSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e73768-5ede-4d89-999c-cebb1f946c56",
   "metadata": {},
   "source": [
    "Types of evaluation metrics (FOR CLASSIFICATION): \n",
    "- True Positive (TP)\n",
    "- True Negative (TN)\n",
    "- False Positive (FP)\n",
    "- False Negative (FN)\n",
    "\n",
    "These all work on each line item of the dataset and using these we will define the evalutaion matrix. \n",
    "- Accuracy : (TP+TN)/all i.e. all true cases / all cases. Overall correctness\n",
    "- Precision : TP/(TP+FP) i.e. How often we are correct.\n",
    "- Recall : TP/(TP+FN) i.e. How many actual spams got caught\n",
    "- F1 score : Harmonic mean : a balance of precision and recall.\n",
    "\n",
    "  F1 = 2*precision *recall/(precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb45987d-0024-47fe-b1a2-4110a164b427",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03f204a-a81a-41fd-b281-05859873f824",
   "metadata": {},
   "source": [
    "Linear Regression is called linear not because of straight line but how you treat the parameters as in in a linear regression you can represnt the parameters like a simple summation or subtraction. \n",
    "A polynomial looking graph can also be a linear regression because it can have linear features inside that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c3819-a962-4610-af82-0481616f0a44",
   "metadata": {},
   "source": [
    "### Flow of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2614e4d-2144-405b-b807-022b4417eea6",
   "metadata": {},
   "source": [
    "Data --> EDA --> FE --> final data\n",
    "\n",
    "Final data --> Train and test \n",
    "\n",
    "Train --> formula say y = mx + c . We start with a random initial value of m & c --> prediction --> error --> gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aa5f6d-c9b3-4882-9d3e-d874fe7d8a22",
   "metadata": {},
   "source": [
    "**Cost function** is the curve obtained when you plot diffeerent values of losses for different values of m1, m2, etc which machine learning finds.\n",
    "\n",
    "https://aero-learn.imperial.ac.uk/vis/Machine%20Learning/gradient_descent_3d.html\n",
    "\n",
    "Ultimately we want to reduce the loss as much as possible possibly zero, We do this by the method of gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d0558f-b5b1-4b79-97cc-cb5c9fc63405",
   "metadata": {},
   "source": [
    "For each value of parameters we get different values of Loss. \n",
    "\n",
    "If we plot all the loss values against the parameter values you get a 3D function as shown in above URL. \n",
    "\n",
    "Ideally we want to have the lowest possible value of Lowest loss, gradient descent is the method that gives you the values of m0, m1, m2 WHICH GIVES THE LOWEST VALUE OF LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ffd023-9b34-4b11-bb6d-42981bd1aedd",
   "metadata": {},
   "source": [
    "**Gradient Descent** : It is an optimisation algorithm used in Machine learning. It is an iterative method used to adjust the parameters if a model to find the minimum loss of a function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8e379-c0f0-4bfc-9fd0-d4048107af26",
   "metadata": {},
   "source": [
    "Loss + loss function ===> Gradient descent = gradient ====> update values of m0, m1, m2. Find the new loss, give to gradient descent and so on.... keep optimising such that the loss no longer decreases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364b485-5a47-446a-ae65-519301e014e2",
   "metadata": {},
   "source": [
    "https://www.playwithml.com/concepts/gradient-descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49896f9d-2a35-44b7-8d5a-c0e98270733d",
   "metadata": {},
   "source": [
    "Goal of Gradient Descent is to find minimum loss. \n",
    "- We use differentiation to calculate slope (gradient) of the cost function at our current position\n",
    "- Slope/gradient will tell us the direction of the steepest ascent (uphill)\n",
    "- Take a step in the opposite direction i.e. towards steepest descent (downhill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ffea8-20bf-4ad9-9dd4-509d03b3888d",
   "metadata": {},
   "source": [
    "Differentiation is simply what will be the rate of change of output when the input changes i.e. value of slope at that point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe12ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58537daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
